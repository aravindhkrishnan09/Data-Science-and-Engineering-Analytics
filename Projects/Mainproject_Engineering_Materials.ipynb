{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e3bd427",
   "metadata": {},
   "source": [
    "# Task 1: Initial Exploration & Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a9c953",
   "metadata": {},
   "source": [
    "# Import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d40248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df1 = pd.read_csv('Data.csv')\n",
    "df2 = pd.read_csv('material.csv')\n",
    "df_original1 = df1.copy()\n",
    "df_original2 = df2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9d794d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa02d119",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df2.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b946f6b",
   "metadata": {},
   "source": [
    "# Identify the total number of materials and heat treatment types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434483b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find distinct values in the 'material' column of df1\n",
    "distinct_materials = df1['Material'].nunique()\n",
    "print(\"Total number of materials in df1:\", len(df1['Material']))\n",
    "print(\"Total number of unique materials in df1:\", distinct_materials)\n",
    "\n",
    "distinct_heat_treatments = df1['Heat treatment'].nunique()\n",
    "print(\"Total number of heat treatments in df1:\", len(df1['Heat treatment']))\n",
    "print(\"Total number of unique heat treatments in df1:\", distinct_heat_treatments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cec4a3",
   "metadata": {},
   "source": [
    "# Check for any missing or inconsistent data values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df460839",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  data_quality_check import data_quality_check\n",
    "data_quality_check(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65693d8a",
   "metadata": {},
   "source": [
    "# Handle Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301a550f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values for objects in df1\n",
    "\n",
    "df1['Heat treatment'] = df1['Heat treatment'].fillna('Unknown')\n",
    "df1['Desc'] = df1['Desc'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ca60f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling anomalies in the 'Sy' column of df1\n",
    "df1['Sy'] = df1['Sy'].str.replace('max', '', regex=False)\n",
    "print(\"Unique values in 'Sy' column before cleaning:\", df1['Sy'].unique())\n",
    "# Change the data type of 'Sy' column to integer\n",
    "df1['Sy'] = df1['Sy'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c1c33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original1['Sy'] = df_original1['Sy'].str.replace('max', '', regex=False)\n",
    "print(\"Unique values in 'Sy' column before cleaning:\", df_original1['Sy'].unique())\n",
    "# Change the data type of 'Sy' column to integer\n",
    "df_original1['Sy'] = df_original1['Sy'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6c486b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with mean for numeric columns in df1\n",
    "for col in df1.select_dtypes(include=['number']).columns:\n",
    "    mean_value = df1[col].mean()\n",
    "    df1[col] = df1[col].fillna(mean_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd0829e",
   "metadata": {},
   "source": [
    "# Identify the column containing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d4d4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = df1.select_dtypes(include=['number']).columns\n",
    "\n",
    "outlier_columns = []\n",
    "for col in numeric_columns:\n",
    "    Q1 = df1[col].quantile(0.25)\n",
    "    Q3 = df1[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    if ((df1[col] < lower_bound) | (df1[col] > upper_bound)).any():\n",
    "        outlier_columns.append(col)\n",
    "\n",
    "print(\"Columns containing outliers:\", outlier_columns)\n",
    "\n",
    "print(\"Number of outliers in each column:\")\n",
    "for col in outlier_columns:\n",
    "    Q1 = df1[col].quantile(0.25)\n",
    "    Q3 = df1[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers_count = ((df1[col] < lower_bound) | (df1[col] > upper_bound)).sum()\n",
    "    print(f\"{col}: {outliers_count} outliers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67926e6f",
   "metadata": {},
   "source": [
    "# Plot the columns containing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b8dfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the columns containing outliers\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def plot_outliers(df, columns):\n",
    "    for col in columns:\n",
    "        plt.figure(figsize=(5, 2))\n",
    "        sns.boxplot(x=df[col], color='lightblue', flierprops=dict(markerfacecolor='red', marker='o'))\n",
    "        \n",
    "        # Calculate statistics\n",
    "        mean_val = df[col].mean()\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        # Add text labels for Q1, Q3, mean, lower bound, and upper bound\n",
    "        stats_text = (f\"Mean: {mean_val:.2f}\\n\"\n",
    "                      f\"25th Percentile (Q1): {Q1:.2f}\\n\"\n",
    "                      f\"75th Percentile (Q3): {Q3:.2f}\\n\"\n",
    "                      f\"Lower Bound: {lower_bound:.2f}\\n\"\n",
    "                      f\"Upper Bound: {upper_bound:.2f}\")\n",
    "        plt.gcf().text(0.85, 0.83, stats_text, fontsize=8, color='black', \n",
    "                       ha='right', va='top', bbox=dict(facecolor='white', alpha=0.5, edgecolor='gray'))\n",
    "        \n",
    "        plt.title(f'Boxplot of {col}')\n",
    "        plt.xlabel(col)\n",
    "        plt.show()\n",
    "\n",
    "plot_outliers(df1, outlier_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d8ad32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle outliers by capping them at lower_bound and upper_bound\n",
    "for col in outlier_columns:\n",
    "    Q1 = df1[col].quantile(0.25)\n",
    "    Q3 = df1[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    df1[col] = df1[col].clip(lower=lower_bound, upper=upper_bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e169b7",
   "metadata": {},
   "source": [
    "# Plot comparison between cleaned data and original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1d6be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "def plot_comparison(df_original1, df1, columns):\n",
    "    # Determine the number of rows and columns for the grid\n",
    "    num_columns = 2  # Number of plots per row\n",
    "    num_rows = len(columns)  # One row per column\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, num_columns, figsize=(15, 5 * num_rows))\n",
    "\n",
    "    for i, col in enumerate(columns):\n",
    "        # Plot for df_original1\n",
    "        sns.histplot(df_original1[col], kde=True, ax=axes[i, 0], color='blue')\n",
    "        mean_val = df_original1[col].mean()\n",
    "        std_val = df_original1[col].std()\n",
    "        max_val = df_original1[col].max()\n",
    "        min_val = df_original1[col].min()\n",
    "        \n",
    "        # Add vertical lines for mean and standard deviation\n",
    "        axes[i, 0].axvline(mean_val, color='red', linestyle='--', label='Mean')\n",
    "        axes[i, 0].axvline(mean_val + std_val, color='green', linestyle='--', label='Mean + Std')\n",
    "        axes[i, 0].axvline(mean_val - std_val, color='green', linestyle='--', label='Mean - Std')\n",
    "        \n",
    "        # Add text box with statistics\n",
    "        stats_text = f\"Mean: {mean_val:.2f}\\nStd: {std_val:.2f}\\nMax: {max_val:.2f}\\nMin: {min_val:.2f}\"\n",
    "        axes[i, 0].text(0.95, 0.95, stats_text, transform=axes[i, 0].transAxes, fontsize=10,\n",
    "                        verticalalignment='top', horizontalalignment='right',\n",
    "                        bbox=dict(facecolor='white', alpha=0.5, edgecolor='gray'))\n",
    "        \n",
    "        axes[i, 0].set_title(f'{col} (df_original1)')\n",
    "        axes[i, 0].set_xlabel(col)\n",
    "        axes[i, 0].set_ylabel('Frequency')\n",
    "\n",
    "        # Plot for df1\n",
    "        sns.histplot(df1[col], kde=True, ax=axes[i, 1], color='green')\n",
    "        mean_val_orig = df1[col].mean()\n",
    "        std_val_orig = df1[col].std()\n",
    "        max_val_orig = df1[col].max()\n",
    "        min_val_orig = df1[col].min()\n",
    "        \n",
    "        # Add vertical lines for mean and standard deviation\n",
    "        axes[i, 1].axvline(mean_val_orig, color='red', linestyle='--', label='Mean')\n",
    "        axes[i, 1].axvline(mean_val_orig + std_val_orig, color='green', linestyle='--', label='Mean + Std')\n",
    "        axes[i, 1].axvline(mean_val_orig - std_val_orig, color='green', linestyle='--', label='Mean - Std')\n",
    "        \n",
    "        # Add text box with statistics\n",
    "        stats_text_orig = f\"Mean: {mean_val_orig:.2f}\\nStd: {std_val_orig:.2f}\\nMax: {max_val_orig:.2f}\\nMin: {min_val_orig:.2f}\"\n",
    "        axes[i, 1].text(0.95, 0.95, stats_text_orig, transform=axes[i, 1].transAxes, fontsize=10,\n",
    "                        verticalalignment='top', horizontalalignment='right',\n",
    "                        bbox=dict(facecolor='white', alpha=0.5, edgecolor='gray'))\n",
    "        \n",
    "        axes[i, 1].set_title(f'{col} (df1)')\n",
    "        axes[i, 1].set_xlabel(col)\n",
    "        axes[i, 1].set_ylabel('Frequency')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with the numeric columns\n",
    "plot_comparison(df_original1, df1, numeric_columns)\n",
    "#plot_comparison(df_original1, df1, ['Su', 'Sy', 'A5'])\n",
    "\n",
    "# Check if the file exists, remove it if it does, and then save the cleaned DataFrame to a new CSV file\n",
    "if os.path.exists('Cleaned_Data.csv'):\n",
    "    os.remove('Cleaned_Data.csv')\n",
    "\n",
    "df1.to_csv('Cleaned_Data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98121298",
   "metadata": {},
   "source": [
    "# Task 2: Groupwise Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313ae3af",
   "metadata": {},
   "source": [
    "# Group average strength, ductility, and hardness values by Material type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa700af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group average strength, ductility, and hardness values by Material type\n",
    "\n",
    "df_grouped_Material = df1.groupby('Material').agg({\n",
    "    'Su': 'mean',\n",
    "    'Sy': 'mean',\n",
    "    'A5': 'mean',\n",
    "    'E': 'mean',\n",
    "    'G': 'mean',\n",
    "    'HV': 'mean'\n",
    "}).reset_index()\n",
    "print(df_grouped_Material.to_string(index=False))\n",
    "\n",
    "df_grouped_Heat = df1.groupby('Heat treatment').agg({\n",
    "    'Su': 'mean',\n",
    "    'Sy': 'mean',\n",
    "    'A5': 'mean',\n",
    "    'E': 'mean',\n",
    "    'G': 'mean',\n",
    "    'HV': 'mean'\n",
    "}).reset_index()\n",
    "print(df_grouped_Heat.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792e1249",
   "metadata": {},
   "source": [
    "# Comparing Efficiency with Material and Heat treatment as seperate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b075e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Define an efficiency metric (e.g., weighted average of properties)\n",
    "df_grouped_Material['Efficiency'] = (df_grouped_Material['Su'] + df_grouped_Material['Sy'] + df_grouped_Material['A5'] + df_grouped_Material['E'] + df_grouped_Material['G'] + df_grouped_Material['HV']) / 6\n",
    "df_grouped_Heat['Efficiency'] = (df_grouped_Heat['Su'] + df_grouped_Heat['Sy'] + df_grouped_Heat['A5'] + df_grouped_Heat['E'] + df_grouped_Heat['G'] + df_grouped_Heat['HV']) / 6\n",
    "\n",
    "# Sort by efficiency\n",
    "df_grouped_sorted_Material = df_grouped_Material.sort_values(by='Efficiency', ascending=False)\n",
    "df_grouped_sorted_Heat = df_grouped_Heat.sort_values(by='Efficiency', ascending=False)\n",
    "\n",
    "# Modify the bar plots to use logarithmic scales for better visualization of differences\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "# Plot the efficiency of each material type using a horizontal bar chart with text values\n",
    "sns.barplot(y='Material', x='Efficiency', data=df_grouped_sorted_Material.head(5), hue='Material', palette='viridis', ax=axes[0], dodge=False)\n",
    "axes[0].set_title('Top 5 Material Types by Efficiency')\n",
    "axes[0].set_xlabel('Efficiency')\n",
    "axes[0].set_ylabel('Material Type')\n",
    "for container in axes[0].containers:\n",
    "    axes[0].bar_label(container, fmt='%.2f', label_type='center', fontsize=8)\n",
    "\n",
    "# Plot the efficiency of each heat treatment type using a horizontal bar chart with text values\n",
    "sns.barplot(y='Heat treatment', x='Efficiency', data=df_grouped_sorted_Heat.head(5), hue='Heat treatment', palette='coolwarm', ax=axes[1], dodge=False)\n",
    "axes[1].set_title('Top 5 Heat Treatment Types by Efficiency')\n",
    "axes[1].set_xlabel('Efficiency')\n",
    "axes[1].set_ylabel('Heat Treatment Type')\n",
    "for container in axes[1].containers:\n",
    "    axes[1].bar_label(container, fmt='%.2f', label_type='center', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f23088",
   "metadata": {},
   "source": [
    "# Group average strength, ductility, and hardness values by Material type and Heat treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b524bbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group average strength, ductility, and hardness values by Material type\n",
    "# Group by both 'Material' and 'Heat treatment' and calculate mean for other columns\n",
    "df_grouped_strength = df1.groupby(['Material', 'Heat treatment']).agg({\n",
    "    'Su': 'mean',\n",
    "    'Sy': 'mean',\n",
    "    'E': 'mean',\n",
    "    'G': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "df_grouped_ductility = df1.groupby(['Material', 'Heat treatment']).agg({\n",
    "    'A5': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "df_grouped_hardness = df1.groupby(['Material', 'Heat treatment']).agg({\n",
    "    'Bhn': 'mean', \n",
    "    'HV': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "print(df_grouped_strength.to_string(index=False))\n",
    "print(df_grouped_ductility.to_string(index=False))\n",
    "print(df_grouped_hardness.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57d0b34",
   "metadata": {},
   "source": [
    "# Plot average strength, ductility, and hardness values by Material type and Heat treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d064c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Define an efficiency metric (e.g., weighted average of properties)\n",
    "df_grouped_strength['Efficiency'] = (df_grouped_strength['Su'] \n",
    "                                     + df_grouped_strength['Sy'] \n",
    "                                     + df_grouped_strength['E'] \n",
    "                                     + df_grouped_strength['G']) / 4\n",
    "df_grouped_ductility['Efficiency'] = df_grouped_ductility['A5'] / 1\n",
    "df_grouped_hardness['Efficiency'] = (df_grouped_hardness['Bhn'] \n",
    "                                     + df_grouped_hardness['HV']) / 2 \n",
    "\n",
    "# Sort by efficiency\n",
    "df_grouped_sorted_strength = df_grouped_strength.sort_values(by='Efficiency', ascending=False)\n",
    "df_grouped_sorted_ductility = df_grouped_ductility.sort_values(by='Efficiency', ascending=False)\n",
    "df_grouped_sorted_hardness = df_grouped_hardness.sort_values(by='Efficiency', ascending=False)\n",
    "\n",
    "# Create subplots for strength, ductility, and hardness grouped by both Material and Heat treatment\n",
    "fig, axes = plt.subplots(3, 1, figsize=(10, 15))\n",
    "\n",
    "# Plot the efficiency of each material and heat treatment type for strength\n",
    "sns.barplot(y='Material', x='Efficiency', hue='Heat treatment', data=df_grouped_sorted_strength.head(5), palette='viridis', ax=axes[0], dodge=False)\n",
    "axes[0].set_title('Top 5 Material and Heat Treatment Types by Strength Efficiency')\n",
    "axes[0].set_xlabel('Efficiency')\n",
    "axes[0].set_ylabel('Material Type')\n",
    "axes[0].legend(title='Heat Treatment', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "for container in axes[0].containers:\n",
    "    axes[0].bar_label(container, fmt='%.2f', label_type='center', fontsize=8)\n",
    "\n",
    "# Plot the efficiency of each material and heat treatment type for ductility\n",
    "sns.barplot(y='Material', x='Efficiency', hue='Heat treatment', data=df_grouped_sorted_ductility.head(5), palette='coolwarm', ax=axes[1], dodge=False)\n",
    "axes[1].set_title('Top 5 Material and Heat Treatment Types by Ductility Efficiency')\n",
    "axes[1].set_xlabel('Efficiency')\n",
    "axes[1].set_ylabel('Material Type')\n",
    "axes[1].legend(title='Heat Treatment', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "for container in axes[1].containers:\n",
    "    axes[1].bar_label(container, fmt='%.2f', label_type='center', fontsize=8)\n",
    "\n",
    "# Plot the efficiency of each material and heat treatment type for hardness\n",
    "sns.barplot(y='Material', x='Efficiency', hue='Heat treatment', data=df_grouped_sorted_hardness.head(5), palette='magma', ax=axes[2], dodge=False)\n",
    "axes[2].set_title('Top 5 Material and Heat Treatment Types by Hardness Efficiency')\n",
    "axes[2].set_xlabel('Efficiency')\n",
    "axes[2].set_ylabel('Material Type')\n",
    "axes[2].legend(title='Heat Treatment', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "for container in axes[2].containers:\n",
    "    axes[2].bar_label(container, fmt='%.2f', label_type='center', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a81fad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top 5 Material Efficiency:\")\n",
    "print(df_grouped_sorted_Material.head(5).to_string(index=False))\n",
    "\n",
    "print(\"\\nTop 5 Heat Treatment Types Efficiency:\")\n",
    "print(df_grouped_sorted_Heat.head(5).to_string(index=False))\n",
    "\n",
    "print(\"\\nTop 5 Material and Heat Treatment Types by Strength Efficiency:\")\n",
    "print(df_grouped_sorted_strength.head(5).to_string(index=False))\n",
    "\n",
    "print(\"\\nTop 5 Material and Heat Treatment Types by Ductility Efficiency:\")\n",
    "print(df_grouped_sorted_ductility.head(5).to_string(index=False))\n",
    "\n",
    "print(\"\\nTop 5 Material and Heat Treatment Types by Hardness Efficiency:\")\n",
    "print(df_grouped_sorted_hardness.head(5).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba0521b",
   "metadata": {},
   "source": [
    "# Task 3: Design Ratio Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aba8057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Calculate the custom metrics\n",
    "df1['Strength_Hardness'] = df1['Su'] / df1['Bhn']           \n",
    "df1['Strength_Ductility'] = df1['Su'] * df1['A5']           \n",
    "df1['Strength_Weight'] = df1['Su'] / df1['Ro']              \n",
    "\n",
    "# Rank the materials based on the custom metrics\n",
    "df1['Strength_Hardness_Rank'] = df1['Strength_Hardness'].rank(ascending=False, method='dense')\n",
    "df1['Strength_Ductility_Rank'] = df1['Strength_Ductility'].rank(ascending=False, method='dense')\n",
    "df1['Strength_Weight_Rank'] = df1['Strength_Weight'].rank(ascending=False, method='dense')\n",
    "\n",
    "# Save the DataFrame with custom metrics to a new CSV file\n",
    "# delete the csv file if it exists\n",
    "import os\n",
    "if os.path.exists('Data_with_custom_metrics.csv'):\n",
    "    os.remove('Data_with_custom_metrics.csv')\n",
    "\n",
    "df1.to_csv('Data_with_custom_metrics.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319d2dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top 5 Materials by Strength-to-Hardness Ratio:\")\n",
    "\n",
    "strength_hardness_table = df1[['Material', 'Strength_Hardness', 'Strength_Hardness_Rank']].sort_values(by='Strength_Hardness_Rank').head(5)\n",
    "if os.path.exists('Top_5_Strength_Hardness.csv'):\n",
    "    os.remove('Top_5_Strength_Hardness.csv')\n",
    "strength_hardness_table.to_csv('Top_5_Strength_Hardness.csv', index=False)\n",
    "print(strength_hardness_table.to_string(index=False))\n",
    "\n",
    "print(\"\\nTop 5 Materials by Strength-to-Ductility Index:\")\n",
    "\n",
    "strength_ductility_table = df1[['Material', 'Strength_Ductility', 'Strength_Ductility_Rank']].sort_values(by='Strength_Ductility_Rank').head(5)\n",
    "if os.path.exists('Top_5_Strength_Ductility.csv'):\n",
    "    os.remove('Top_5_Strength_Ductility.csv')\n",
    "strength_ductility_table.to_csv('Top_5_Strength_Ductility.csv', index=False)\n",
    "print(strength_ductility_table.to_string(index=False))\n",
    "\n",
    "print(\"\\nTop 5 Materials by Strength-to-Weight Proxy:\")\n",
    "\n",
    "strength_weight_table = df1[['Material', 'Strength_Weight', 'Strength_Weight_Rank']].sort_values(by='Strength_Weight_Rank').head(5)\n",
    "if os.path.exists('Top_5_Strength_Weight.csv'):\n",
    "    os.remove('Top_5_Strength_Weight.csv')\n",
    "strength_weight_table.to_csv('Top_5_Strength_Weight.csv', index=False)\n",
    "print(strength_weight_table.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37743dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342c1618",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "# Plot Strength-to-Hardness Ratio as a heatmap\n",
    "sns.heatmap(strength_hardness_table.pivot_table(index='Material', values='Strength_Hardness'), \n",
    "            annot=True, fmt=\".2f\", cmap='Blues', ax=axes[0], cbar=False)\n",
    "axes[0].set_title('Top 5 Materials by Strength-to-Hardness Ratio')\n",
    "axes[0].set_xlabel('Strength-to-Hardness Ratio')\n",
    "axes[0].set_ylabel('Material')\n",
    "\n",
    "# Plot Strength-to-Ductility Index as a heatmap\n",
    "sns.heatmap(strength_ductility_table.pivot_table(index='Material', values='Strength_Ductility'), \n",
    "            annot=True, fmt=\".2f\", cmap='Greens', ax=axes[1], cbar=False)\n",
    "axes[1].set_title('Top 5 Materials by Strength-to-Ductility Index')\n",
    "axes[1].set_xlabel('Strength-to-Ductility Index')\n",
    "axes[1].set_ylabel('Material')\n",
    "\n",
    "# Plot Strength-to-Weight Proxy as a heatmap\n",
    "sns.heatmap(strength_weight_table.pivot_table(index='Material', values='Strength_Weight'), \n",
    "            annot=True, fmt=\".2f\", cmap='Reds', ax=axes[2], cbar=False)\n",
    "axes[2].set_title('Top 5 Materials by Strength-to-Weight Proxy')\n",
    "axes[2].set_xlabel('Strength-to-Weight Proxy')\n",
    "axes[2].set_ylabel('Material')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
