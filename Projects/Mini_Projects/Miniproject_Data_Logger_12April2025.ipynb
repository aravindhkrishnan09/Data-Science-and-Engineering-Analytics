{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b42417e7",
   "metadata": {},
   "source": [
    "# Test Bench Data Logger\n",
    "This project merges multiple logs, cleans data, transforms fields, and prepares an exportable summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a2cb5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89aa5f74",
   "metadata": {},
   "source": [
    "## Merge Multiple Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cea4a593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    timestamp  sensor_id      value\n",
      "0  2025-01-01 08:53:51.756968          4  10.806067\n",
      "1  2025-01-10 16:52:01.575376          3  42.337052\n",
      "2  2025-01-04 09:19:31.948991          3  51.626520\n",
      "3  2025-01-10 01:13:29.128424          1  49.903567\n",
      "4  2025-01-01 23:49:55.384271          5  73.334637\n"
     ]
    }
   ],
   "source": [
    "# Specify the directory containing log files\n",
    "log_dir = 'G:\\\\DIY Guru\\\\Data-Science-and-Engineering-Analytics\\\\sample_logs'\n",
    "\n",
    "# Read and merge all CSV files\n",
    "all_logs = []\n",
    "for file in os.listdir(log_dir):\n",
    "    if file.endswith('.csv'):\n",
    "        file_path = os.path.join(log_dir, file)\n",
    "        log = pd.read_csv(file_path)\n",
    "        all_logs.append(log)\n",
    "\n",
    "# Combine all logs into a single DataFrame\n",
    "merged_logs = pd.concat(all_logs, ignore_index=True)\n",
    "print(merged_logs.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9645bd9",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a33d40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 808 entries, 0 to 807\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   timestamp  808 non-null    object \n",
      " 1   sensor_id  808 non-null    int64  \n",
      " 2   value      808 non-null    float64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 19.1+ KB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_9084\\206211869.py:5: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_logs.fillna(method='ffill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicate rows\n",
    "merged_logs.drop_duplicates(inplace=True)\n",
    "\n",
    "# Handle missing values\n",
    "merged_logs.fillna(method='ffill', inplace=True)\n",
    "print(merged_logs.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca34986",
   "metadata": {},
   "source": [
    "## Transform Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "101e7de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   timestamp  sensor_id     value\n",
      "0 2025-01-01 08:53:51.756968          4 -1.674792\n",
      "1 2025-01-10 16:52:01.575376          3 -0.488350\n",
      "2 2025-01-04 09:19:31.948991          3 -0.138807\n",
      "3 2025-01-10 01:13:29.128424          1 -0.203638\n",
      "4 2025-01-01 23:49:55.384271          5  0.678021\n"
     ]
    }
   ],
   "source": [
    "# Example: Convert timestamp to datetime\n",
    "merged_logs['timestamp'] = pd.to_datetime(merged_logs['timestamp'])\n",
    "\n",
    "# Example: Normalize a numeric field\n",
    "merged_logs['value'] = (merged_logs['value'] - merged_logs['value'].mean()) / merged_logs['value'].std()\n",
    "print(merged_logs.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b78e87b",
   "metadata": {},
   "source": [
    "## Prepare Exportable Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3898fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           timestamp   sensor_id         value\n",
      "count                            808  808.000000  8.080000e+02\n",
      "mean   2025-01-05 20:10:26.220852480    4.949257 -1.099231e-17\n",
      "min       2025-01-01 00:13:43.843506    1.000000 -1.698531e+00\n",
      "25%    2025-01-03 09:43:50.470497792    3.000000 -8.674178e-01\n",
      "50%    2025-01-05 15:57:28.988634880    5.000000 -1.346758e-02\n",
      "75%    2025-01-08 07:43:55.770214400    7.000000  8.944221e-01\n",
      "max       2025-01-10 23:51:10.179814    9.000000  1.681137e+00\n",
      "std                              NaN    2.577887  1.000000e+00\n",
      "Summary statistics saved to summary_statistics.csv\n"
     ]
    }
   ],
   "source": [
    "#Exportable Summary\n",
    "summary = merged_logs.describe()\n",
    "summary.to_csv('summary_statistics.csv', index=False)\n",
    "print(summary)\n",
    "print(\"Summary statistics saved to summary_statistics.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
