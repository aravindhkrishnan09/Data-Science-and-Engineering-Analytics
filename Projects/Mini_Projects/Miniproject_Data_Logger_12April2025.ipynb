{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b42417e7",
   "metadata": {},
   "source": [
    "# Test Bench Data Logger\n",
    "This project merges multiple logs, cleans data, transforms fields, and prepares an exportable summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a2cb5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89aa5f74",
   "metadata": {},
   "source": [
    "## Merge Multiple Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cea4a593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    timestamp  sensor_id      value\n",
      "0  2025-01-09 19:01:51.680019          1  81.502427\n",
      "1  2025-01-06 15:40:01.428892          5  76.684361\n",
      "2  2025-01-03 19:46:38.810853          2  70.723500\n",
      "3  2025-01-08 08:04:37.900929          1  28.359448\n",
      "4  2025-01-02 16:34:57.811176          3  10.296229\n"
     ]
    }
   ],
   "source": [
    "# Specify the directory containing log files\n",
    "log_dir = r\"G:\\DIYguru\\Data-Science-and-Engineering-Analytics\\Projects\\Mini_Projects\\sample_logs\"\n",
    "\n",
    "# Read and merge all CSV files\n",
    "all_logs = []\n",
    "for file in os.listdir(log_dir):\n",
    "    if file.endswith('.csv'):\n",
    "        file_path = os.path.join(log_dir, file)\n",
    "        log = pd.read_csv(file_path)\n",
    "        all_logs.append(log)\n",
    "\n",
    "# Combine all logs into a single DataFrame\n",
    "merged_logs = pd.concat(all_logs, ignore_index=True)\n",
    "print(merged_logs.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9645bd9",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a33d40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_14812\\206211869.py:5: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_logs.fillna(method='ffill', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 823 entries, 0 to 822\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   timestamp  823 non-null    object \n",
      " 1   sensor_id  823 non-null    int64  \n",
      " 2   value      823 non-null    float64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 19.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicate rows\n",
    "merged_logs.drop_duplicates(inplace=True)\n",
    "\n",
    "# Handle missing values\n",
    "merged_logs.fillna(method='ffill', inplace=True)\n",
    "print(merged_logs.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca34986",
   "metadata": {},
   "source": [
    "## Transform Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "101e7de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   timestamp  sensor_id     value\n",
      "0 2025-01-09 19:01:51.680019          1  1.001285\n",
      "1 2025-01-06 15:40:01.428892          5  0.817754\n",
      "2 2025-01-03 19:46:38.810853          2  0.590692\n",
      "3 2025-01-08 08:04:37.900929          1 -1.023045\n",
      "4 2025-01-02 16:34:57.811176          3 -1.711111\n"
     ]
    }
   ],
   "source": [
    "# Example: Convert timestamp to datetime\n",
    "merged_logs['timestamp'] = pd.to_datetime(merged_logs['timestamp'])\n",
    "\n",
    "# Example: Normalize a numeric field\n",
    "merged_logs['value'] = (merged_logs['value'] - merged_logs['value'].mean()) / merged_logs['value'].std()\n",
    "print(merged_logs.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b78e87b",
   "metadata": {},
   "source": [
    "## Prepare Exportable Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3898fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           timestamp   sensor_id         value\n",
      "count                            823  823.000000  8.230000e+02\n",
      "mean   2025-01-06 03:13:14.253918208    5.036452 -8.849408e-17\n",
      "min       2025-01-01 00:01:34.123960    1.000000 -1.721807e+00\n",
      "25%    2025-01-03 14:05:57.874546944    3.000000 -8.557974e-01\n",
      "50%    2025-01-06 04:46:21.899525120    5.000000  4.045858e-02\n",
      "75%    2025-01-08 13:34:39.058206464    7.000000  8.889155e-01\n",
      "max       2025-01-10 23:29:43.020769    9.000000  1.705544e+00\n",
      "std                              NaN    2.621942  1.000000e+00\n",
      "Summary statistics saved to summary_statistics.csv\n"
     ]
    }
   ],
   "source": [
    "#Exportable Summary\n",
    "summary = merged_logs.describe()\n",
    "summary.to_csv('summary_statistics.csv', index=False)\n",
    "print(summary)\n",
    "print(\"Summary statistics saved to summary_statistics.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
