{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b219342f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g:\\DIYguru\\Data-Science-and-Engineering-Analytics\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "494fc5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Created a function 'load_data_excel' to load excel into python\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def load_data_excel(file_path):\n",
    "    \"\"\"\n",
    "    Load data from an Excel file and return a DataFrame.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"The file {file_path} does not exist.\")\n",
    "    \n",
    "    df = pd.read_excel(file_path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9624fc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Loaded VED_Static_Data_ICE&HEV into dataframe df_ICE_HEV using the above function\n",
    "Loaded VED_Static_Data_PHEV&EV into dataframe df_PHEV_EV using the above function\n",
    "'''\n",
    "\n",
    "DATA_DIR = load_data_excel(\"G:\\\\DIYguru\\\\Notes and Sample Data\\\\VED-master\\\\Data\\\\VED_Static_Data_ICE&HEV.xlsx\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9785cd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def load_files_from_directory(directory_path, file_types=('csv', 'xls', 'xlsx')):\n",
    "    \"\"\"\n",
    "    Load and append CSV and Excel files from a given directory into a single pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        directory_path (str): Path to the directory containing the files.\n",
    "        file_types (tuple): File types to load. Default is ('csv', 'xls', 'xlsx').\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A single DataFrame containing data from all files.\n",
    "    \"\"\"\n",
    "    dataframes = []\n",
    "    for filename in os.listdir(directory_path):\n",
    "        filepath = os.path.join(directory_path, filename)\n",
    "        if os.path.isfile(filepath):\n",
    "            ext = filename.lower().split('.')[-1]\n",
    "            try:\n",
    "                if ext == 'csv' and 'csv' in file_types:\n",
    "                    df = pd.read_csv(filepath)\n",
    "                    dataframes.append(df)\n",
    "                elif ext in ['xls', 'xlsx'] and ext in file_types:\n",
    "                    df = pd.read_excel(filepath)\n",
    "                    dataframes.append(df)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to load {filename}: {e}\")\n",
    "    if dataframes:\n",
    "        return pd.concat(dataframes, ignore_index=True)\n",
    "    else:\n",
    "        return pd.DataFrame()  # Return an empty DataFrame if no files are loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6eae1645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined DataFrame shape: (5843, 49)\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = r\"G:\\DIYguru\\Notes and Sample Data\\DEVRT\\DEVRT\\NISSAN LEAF\"\n",
    "DATA_DIR = load_files_from_directory(DATA_DIR)\n",
    "\n",
    "print(f\"Combined DataFrame shape: {DATA_DIR.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99d00890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your S3 Buckets:\n",
      " - s3aravindh973515031797\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This cell loads AWS credentials from a .env file using python-dotenv,\n",
    "creates a boto3 S3 client with those credentials,\n",
    "and lists all S3 buckets in the account.\n",
    "'''\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import boto3\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Create boto3 client using loaded environment variables\n",
    "s3 = boto3.client(\"s3\",\n",
    "    aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
    "    aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "    region_name=os.getenv(\"AWS_DEFAULT_REGION\")\n",
    ")\n",
    "\n",
    "# Example: list buckets\n",
    "buckets = s3.list_buckets()\n",
    "print(\"Your S3 Buckets:\")\n",
    "for bucket in buckets['Buckets']:\n",
    "    print(f\" - {bucket['Name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f9748e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned up VED Source Data/\n",
      "Cleaned up VED Source Data/df_ICE_HEV.parquet\n",
      "Cleaned up VED Source Data/df_PHEV_EV.parquet\n",
      "Cleaned up VED Source Data/df_VED.parquet\n",
      "Cleaned up VED Source Data/df_combined.parquet\n",
      "Cleaned up VED Source Data/df_dynamic_sample.parquet\n",
      "Cleaned up VED Source Data/df_static.parquet\n",
      "DIYguru ML Source Data/\n",
      "DIYguru ML Source Data/VED_DynamicData_Part1/VED_171101_week.csv\n",
      "DIYguru ML Source Data/VED_DynamicData_Part1/VED_171108_week.csv\n",
      "DIYguru ML Source Data/VED_DynamicData_Part1/VED_171115_week.csv\n",
      "DIYguru ML Source Data/VED_DynamicData_Part1/VED_171122_week.csv\n",
      "DIYguru ML Source Data/VED_DynamicData_Part1/VED_171129_week.csv\n",
      "DIYguru ML Source Data/VED_DynamicData_Part1/VED_171206_week.csv\n",
      "DIYguru ML Source Data/VED_DynamicData_Part1/VED_171213_week.csv\n",
      "DIYguru ML Source Data/VED_DynamicData_Part1/VED_171220_week.csv\n",
      "DIYguru ML Source Data/VED_DynamicData_Part1/VED_171227_week.csv\n",
      "DIYguru ML Source Data/VED_DynamicData_Part1/VED_180103_week.csv\n",
      "DIYguru ML Source Data/VED_DynamicData_Part1/VED_180110_week.csv\n",
      "DIYguru ML Source Data/VED_DynamicData_Part1/VED_180117_week.csv\n",
      "DIYguru ML Source Data/VED_DynamicData_Part1/VED_180124_week.csv\n",
      "DIYguru ML Source Data/VED_DynamicData_Part1/VED_180131_week.csv\n",
      "DIYguru ML Source Data/VED_DynamicData_Part1/VED_180207_week.csv\n",
      "DIYguru ML Source Data/VED_DynamicData_Part1/VED_180214_week.csv\n",
      "DIYguru ML Source Data/VED_DynamicData_Part1/VED_180221_week.csv\n",
      "DIYguru ML Source Data/VED_DynamicData_Part1/VED_180228_week.csv\n",
      "DIYguru ML Source Data/VED_DynamicData_Part1/VED_180307_week.csv\n",
      "DIYguru ML Source Data/VED_DynamicData_Part1/VED_180314_week.csv\n",
      "DIYguru ML Source Data/VED_DynamicData_Part1/VED_180321_week.csv\n",
      "DIYguru ML Source Data/VED_DynamicData_Part1/VED_180328_week.csv\n",
      "DIYguru ML Source Data/VED_Static_Data_ICE&HEV.xlsx\n",
      "DIYguru ML Source Data/VED_Static_Data_PHEV&EV.xlsx\n",
      "NISSAN LEAF/NISSAN_LEAF.parquet\n"
     ]
    }
   ],
   "source": [
    "bucket_name = 's3aravindh973515031797'\n",
    "\n",
    "response = s3.list_objects_v2(Bucket=bucket_name)\n",
    "for item in response.get(\"Contents\", []):\n",
    "    print(item[\"Key\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a87b0e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def push_df_to_s3_parquet(df, object_key):\n",
    "    \"\"\"\n",
    "    Pushes a pandas DataFrame to a predefined S3 bucket as a Parquet file.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame to upload.\n",
    "        object_key (str): S3 object key (path/filename.parquet).\n",
    "    \"\"\"\n",
    "    from io import BytesIO\n",
    "    parquet_buffer = BytesIO()\n",
    "    df.to_parquet(parquet_buffer, index=False)\n",
    "    parquet_buffer.seek(0)\n",
    "    s3.upload_fileobj(parquet_buffer, bucket_name, object_key)\n",
    "    print(f\"DataFrame uploaded to s3://{bucket_name}/{object_key}\")\n",
    "\n",
    "# Example usage:\n",
    "# push_df_to_s3_parquet(df_static, 'path/to/df_static.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd751f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame uploaded to s3://s3aravindh973515031797/NISSAN LEAF/NISSAN_LEAF.parquet\n"
     ]
    }
   ],
   "source": [
    "push_df_to_s3_parquet(DATA_DIR, 'NISSAN LEAF/NISSAN_LEAF.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8527b364",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "\n",
    "def read_parquet_from_s3(bucket_name, object_key):\n",
    "        \"\"\"\n",
    "        Reads a Parquet file from an AWS S3 bucket using the global s3 client.\n",
    "\n",
    "        Args:\n",
    "            bucket_name: Name of the S3 bucket.\n",
    "            object_key: Key (path) to the Parquet file in the S3 bucket.\n",
    "\n",
    "        Returns:\n",
    "            DataFrame containing the Parquet data.\n",
    "        \"\"\"\n",
    "        response = s3.get_object(Bucket=bucket_name, Key=object_key)\n",
    "        file_content = response['Body'].read()\n",
    "        df = pd.read_parquet(BytesIO(file_content))\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0af44164",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 's3aravindh973515031797'\n",
    "df = 'NISSAN LEAF/NISSAN_LEAF.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d121820f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_parquet_from_s3(bucket_name, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f353365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp_data_utc</th>\n",
       "      <th>elv_spy</th>\n",
       "      <th>speed</th>\n",
       "      <th>soc</th>\n",
       "      <th>amb_temp</th>\n",
       "      <th>soh</th>\n",
       "      <th>regenwh</th>\n",
       "      <th>Motor Pwr(w)</th>\n",
       "      <th>Aux Pwr(100w)</th>\n",
       "      <th>Motor Temp</th>\n",
       "      <th>...</th>\n",
       "      <th>cars_by_speed_interval_80_100</th>\n",
       "      <th>cars_by_speed_interval_100_120</th>\n",
       "      <th>cars_by_speed_interval_0_50</th>\n",
       "      <th>cars_by_speed_interval_50_80</th>\n",
       "      <th>cars_by_speed_interval_80_120</th>\n",
       "      <th>cars_by_speed_interval_120_inf</th>\n",
       "      <th>cars_by_length_interval_0_7</th>\n",
       "      <th>cars_by_length_interval_7_inf</th>\n",
       "      <th>max_speed</th>\n",
       "      <th>radius</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18/04/2023 11:33</td>\n",
       "      <td>98</td>\n",
       "      <td>12.7</td>\n",
       "      <td>87</td>\n",
       "      <td>17.5</td>\n",
       "      <td>99.27</td>\n",
       "      <td>-617</td>\n",
       "      <td>1520</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>...</td>\n",
       "      <td>47.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>30</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18/04/2023 11:33</td>\n",
       "      <td>98</td>\n",
       "      <td>32.1</td>\n",
       "      <td>87</td>\n",
       "      <td>17.5</td>\n",
       "      <td>99.27</td>\n",
       "      <td>-617</td>\n",
       "      <td>6200</td>\n",
       "      <td>2</td>\n",
       "      <td>89</td>\n",
       "      <td>...</td>\n",
       "      <td>47.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>30</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18/04/2023 11:33</td>\n",
       "      <td>98</td>\n",
       "      <td>30.7</td>\n",
       "      <td>87</td>\n",
       "      <td>17.5</td>\n",
       "      <td>99.27</td>\n",
       "      <td>-617</td>\n",
       "      <td>9480</td>\n",
       "      <td>2</td>\n",
       "      <td>89</td>\n",
       "      <td>...</td>\n",
       "      <td>47.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>55</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18/04/2023 11:33</td>\n",
       "      <td>98</td>\n",
       "      <td>34.4</td>\n",
       "      <td>87</td>\n",
       "      <td>17.5</td>\n",
       "      <td>99.27</td>\n",
       "      <td>-617</td>\n",
       "      <td>1960</td>\n",
       "      <td>2</td>\n",
       "      <td>89</td>\n",
       "      <td>...</td>\n",
       "      <td>47.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>25</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18/04/2023 11:33</td>\n",
       "      <td>98</td>\n",
       "      <td>20.9</td>\n",
       "      <td>87</td>\n",
       "      <td>17.5</td>\n",
       "      <td>99.27</td>\n",
       "      <td>-626</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>...</td>\n",
       "      <td>47.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>90</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  timestamp_data_utc  elv_spy  speed  soc  amb_temp    soh  regenwh  \\\n",
       "0   18/04/2023 11:33       98   12.7   87      17.5  99.27     -617   \n",
       "1   18/04/2023 11:33       98   32.1   87      17.5  99.27     -617   \n",
       "2   18/04/2023 11:33       98   30.7   87      17.5  99.27     -617   \n",
       "3   18/04/2023 11:33       98   34.4   87      17.5  99.27     -617   \n",
       "4   18/04/2023 11:33       98   20.9   87      17.5  99.27     -626   \n",
       "\n",
       "   Motor Pwr(w)  Aux Pwr(100w)  Motor Temp  ...  \\\n",
       "0          1520              2          90  ...   \n",
       "1          6200              2          89  ...   \n",
       "2          9480              2          89  ...   \n",
       "3          1960              2          89  ...   \n",
       "4             0              2          88  ...   \n",
       "\n",
       "   cars_by_speed_interval_80_100  cars_by_speed_interval_100_120  \\\n",
       "0                           47.0                           239.0   \n",
       "1                           47.0                           239.0   \n",
       "2                           47.0                           239.0   \n",
       "3                           47.0                           239.0   \n",
       "4                           47.0                           239.0   \n",
       "\n",
       "   cars_by_speed_interval_0_50  cars_by_speed_interval_50_80  \\\n",
       "0                          NaN                           NaN   \n",
       "1                          NaN                           NaN   \n",
       "2                          NaN                           NaN   \n",
       "3                          NaN                           NaN   \n",
       "4                          NaN                           NaN   \n",
       "\n",
       "   cars_by_speed_interval_80_120  cars_by_speed_interval_120_inf  \\\n",
       "0                            NaN                           102.0   \n",
       "1                            NaN                           102.0   \n",
       "2                            NaN                           102.0   \n",
       "3                            NaN                           102.0   \n",
       "4                            NaN                           102.0   \n",
       "\n",
       "  cars_by_length_interval_0_7  cars_by_length_interval_7_inf  max_speed radius  \n",
       "0                       271.0                          118.0         30    3.0  \n",
       "1                       271.0                          118.0         30    3.0  \n",
       "2                       271.0                          118.0         55    3.0  \n",
       "3                       271.0                          118.0         25    3.0  \n",
       "4                       271.0                          118.0         90    3.0  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
